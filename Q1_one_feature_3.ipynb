{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning:\n",
      " avg_temperature    15\n",
      "humidity           15\n",
      "avg_wind_speed     15\n",
      "rain_or_not         0\n",
      "pressure            0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after cleaning:\n",
      " avg_temperature    0\n",
      "humidity           0\n",
      "avg_wind_speed     0\n",
      "rain_or_not        0\n",
      "pressure           0\n",
      "dtype: int64\n",
      "\n",
      "ðŸ”¹ Training model to predict: avg_temperature...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      "ðŸ“Œ RMSE for avg_temperature: 4.14\n",
      "\n",
      "ðŸ”¹ Best Parameters for avg_temperature Regression Model:\n",
      "{'max_depth': None, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "\n",
      "ðŸ“Œ Predictions for avg_temperature:\n",
      "  Day 270: Predicted = 23.88 | Actual = 19.65\n",
      "\n",
      "ðŸ”¹ Training model to predict: humidity...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      "ðŸ“Œ RMSE for humidity: 11.77\n",
      "\n",
      "ðŸ”¹ Best Parameters for humidity Regression Model:\n",
      "{'max_depth': None, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "\n",
      "ðŸ“Œ Predictions for humidity:\n",
      "  Day 270: Predicted = 49.40 | Actual = 42.19\n",
      "\n",
      "ðŸ”¹ Training model to predict: avg_wind_speed...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      "ðŸ“Œ RMSE for avg_wind_speed: 2.76\n",
      "\n",
      "ðŸ”¹ Best Parameters for avg_wind_speed Regression Model:\n",
      "{'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "ðŸ“Œ Predictions for avg_wind_speed:\n",
      "  Day 270: Predicted = 9.61 | Actual = 8.09\n",
      "\n",
      "ðŸ”¹ Training model to predict: pressure...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      "ðŸ“Œ RMSE for pressure: 35.35\n",
      "\n",
      "ðŸ”¹ Best Parameters for pressure Regression Model:\n",
      "{'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "\n",
      "ðŸ“Œ Predictions for pressure:\n",
      "  Day 270: Predicted = 1006.50 | Actual = 964.00\n",
      "\n",
      "ðŸ”¹ Training model to predict 'rain_or_not'...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "\n",
      "ðŸ“Œ Accuracy for 'rain_or_not' on the test set: 0.50\n",
      "\n",
      "ðŸ”¹ Best Parameters for 'rain_or_not' Classification Model:\n",
      "{'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "\n",
      "ðŸ“Œ Predictions for 'rain_or_not':\n",
      "  Day 270: Predicted = Rain | Actual = No Rain\n",
      "\n",
      "ðŸ”¹ Classification Performance Metrics for the last 20 days:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.71         9\n",
      "           1       0.73      1.00      0.85        11\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.87      0.78      0.78        20\n",
      "weighted avg       0.85      0.80      0.79        20\n",
      "\n",
      "\n",
      "ðŸ”¹ Confusion Matrix for the last 20 days:\n",
      "[[ 5  4]\n",
      " [ 0 11]]\n",
      "\n",
      "ðŸ”¹ Evaluating accuracy on the last 20 days...\n",
      "\n",
      "ðŸ“Œ Accuracy for 'rain_or_not' on the last 20 days: 0.80\n",
      "\n",
      "ðŸ“Œ Predictions for 'rain_or_not' on the last 20 days:\n",
      "  Day 276: Predicted = Rain | Actual = Rain\n",
      "  Day 277: Predicted = Rain | Actual = Rain\n",
      "  Day 278: Predicted = Rain | Actual = Rain\n",
      "  Day 279: Predicted = No Rain | Actual = No Rain\n",
      "  Day 280: Predicted = Rain | Actual = Rain\n",
      "  Day 281: Predicted = Rain | Actual = Rain\n",
      "  Day 282: Predicted = Rain | Actual = Rain\n",
      "  Day 283: Predicted = No Rain | Actual = No Rain\n",
      "  Day 284: Predicted = Rain | Actual = Rain\n",
      "  Day 285: Predicted = Rain | Actual = Rain\n",
      "  Day 286: Predicted = No Rain | Actual = No Rain\n",
      "  Day 287: Predicted = Rain | Actual = Rain\n",
      "  Day 288: Predicted = No Rain | Actual = No Rain\n",
      "  Day 289: Predicted = Rain | Actual = Rain\n",
      "  Day 290: Predicted = Rain | Actual = No Rain\n",
      "  Day 291: Predicted = Rain | Actual = No Rain\n",
      "  Day 292: Predicted = Rain | Actual = No Rain\n",
      "  Day 293: Predicted = Rain | Actual = Rain\n",
      "  Day 294: Predicted = No Rain | Actual = No Rain\n",
      "  Day 295: Predicted = Rain | Actual = No Rain\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"weather_data.csv\")  # Replace with your actual dataset path\n",
    "\n",
    "# Remove 'date' and 'cloud_cover' columns if they exist\n",
    "df = df.drop(['date', 'cloud_cover'], axis=1, errors='ignore')\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values before cleaning:\\n\", df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Verify that no missing values remain\n",
    "print(\"\\nMissing values after cleaning:\\n\", df.isnull().sum())\n",
    "\n",
    "# Encode categorical column ('rain_or_not')\n",
    "categorical_columns = ['rain_or_not']\n",
    "le = LabelEncoder()\n",
    "df['rain_or_not'] = le.fit_transform(df['rain_or_not'])  # Convert to binary (0 or 1)\n",
    "\n",
    "# Number of past days to use as features\n",
    "N = 270  \n",
    "\n",
    "# Dictionary to store predictions and feature importance\n",
    "predictions = {}\n",
    "feature_importance = {}\n",
    "\n",
    "# Separate 'rain_or_not' (classification) from numeric columns (regression)\n",
    "numerical_columns = df.drop(columns=['rain_or_not']).columns.tolist()\n",
    "\n",
    "# ðŸ”¹ Predicting numerical values using RandomForestRegressor\n",
    "for target_col in numerical_columns:\n",
    "    print(f\"\\nðŸ”¹ Training model to predict: {target_col}...\")\n",
    "\n",
    "    # Create feature set (X) and target set (y)\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(N, len(df)):\n",
    "        X.append(df[target_col].iloc[i-N:i].values)  # Use previous N days of the target column\n",
    "        y.append(df[target_col].iloc[i])  # Target value for prediction\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Split into train, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "    # ðŸ”¹ Hyperparameter tuning using Grid Search\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 10],\n",
    "        'max_depth': [None],\n",
    "        'min_samples_split': [2]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_  # Select best model from grid search\n",
    "\n",
    "    # Store predictions\n",
    "    target_predictions = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, target_predictions))\n",
    "    print(f\"\\nðŸ“Œ RMSE for {target_col}: {rmse:.2f}\")\n",
    "\n",
    "    # Store feature importance\n",
    "    feature_importance[target_col] = best_model.feature_importances_\n",
    "\n",
    "    # Output best parameters for regression model\n",
    "    print(f\"\\nðŸ”¹ Best Parameters for {target_col} Regression Model:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # Print some predicted vs. actual values for reference\n",
    "    print(f\"\\nðŸ“Œ Predictions for {target_col}:\")\n",
    "    for i in range(0, len(y_test), 10):  # Print every 10th prediction\n",
    "        print(f\"  Day {N + i}: Predicted = {target_predictions[i]:.2f} | Actual = {y_test[i]:.2f}\")\n",
    "\n",
    "# ðŸ”¹ Predicting 'rain_or_not' using RandomForestClassifier\n",
    "print(\"\\nðŸ”¹ Training model to predict 'rain_or_not'...\")\n",
    "\n",
    "X, y = [], []\n",
    "for i in range(N, len(df)):\n",
    "    X.append(df.drop(columns=['rain_or_not']).iloc[i-N:i].values.flatten())  # Use all other features\n",
    "    y.append(df['rain_or_not'].iloc[i])  # Target label (rain or not)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "# ðŸ”¹ Hyperparameter tuning for classification\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 10],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [5, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_classifier = grid_search.best_estimator_  # Select best model from grid search\n",
    "\n",
    "# Store predictions\n",
    "rain_predictions = best_classifier.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, rain_predictions)\n",
    "print(f\"\\nðŸ“Œ Accuracy for 'rain_or_not' on the test set: {accuracy:.2f}\")\n",
    "\n",
    "# Output best parameters for classification model\n",
    "print(f\"\\nðŸ”¹ Best Parameters for 'rain_or_not' Classification Model:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Print some predicted vs. actual values\n",
    "print(\"\\nðŸ“Œ Predictions for 'rain_or_not':\")\n",
    "for i in range(0, len(y_test), 10):  # Print every 10th prediction\n",
    "    print(f\"  Day {N + i}: Predicted = {'Rain' if rain_predictions[i] == 1 else 'No Rain'} | Actual = {'Rain' if y_test[i] == 1 else 'No Rain'}\")\n",
    "\n",
    "# ðŸ”¹ Performance metrics for the last 20 days (instead of full test set)\n",
    "print(\"\\nðŸ”¹ Classification Performance Metrics for the last 20 days:\")\n",
    "\n",
    "# Get the classification performance metrics on the last 20 days\n",
    "print(classification_report(last_20_days_actual, last_20_days_predictions))\n",
    "\n",
    "# ðŸ”¹ Confusion Matrix for the last 20 days\n",
    "conf_matrix_last_20 = confusion_matrix(last_20_days_actual, last_20_days_predictions)\n",
    "print(\"\\nðŸ”¹ Confusion Matrix for the last 20 days:\")\n",
    "print(conf_matrix_last_20)\n",
    "\n",
    "# ðŸ”¹ Evaluating accuracy on the last 20 days\n",
    "print(\"\\nðŸ”¹ Evaluating accuracy on the last 20 days...\")\n",
    "\n",
    "last_20_days_features = []\n",
    "last_20_days_actual = y[-20:]\n",
    "\n",
    "for i in range(len(df) - 20, len(df)):\n",
    "    last_20_days_features.append(df.drop(columns=['rain_or_not']).iloc[i-N:i].values.flatten())\n",
    "\n",
    "last_20_days_features = np.array(last_20_days_features)\n",
    "\n",
    "# Make predictions for the last 20 days\n",
    "last_20_days_predictions = best_classifier.predict(last_20_days_features)\n",
    "\n",
    "# Calculate accuracy on the last 20 days\n",
    "last_20_days_accuracy = accuracy_score(last_20_days_actual, last_20_days_predictions)\n",
    "print(f\"\\nðŸ“Œ Accuracy for 'rain_or_not' on the last 20 days: {last_20_days_accuracy:.2f}\")\n",
    "\n",
    "# Print some predicted vs. actual values for the last 20 days\n",
    "print(\"\\nðŸ“Œ Predictions for 'rain_or_not' on the last 20 days:\")\n",
    "for i in range(len(last_20_days_predictions)):\n",
    "    print(f\"  Day {len(df)-20 + i}: Predicted = {'Rain' if last_20_days_predictions[i] == 1 else 'No Rain'} | Actual = {'Rain' if last_20_days_actual[i] == 1 else 'No Rain'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Predicting for Day 297...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1184 features, but RandomForestClassifier is expecting 1080 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m future_features \u001b[38;5;241m=\u001b[39m today_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrain_or_not\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Predict 'rain_or_not' for the next day\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m future_rain_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mbest_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m future_predictions_rain\u001b[38;5;241m.\u001b[39mappend(future_rain_prediction[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Now update today_data for the next iteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thili\\radioconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\thili\\radioconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\thili\\radioconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\thili\\radioconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\thili\\radioconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2832\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1184 features, but RandomForestClassifier is expecting 1080 features as input."
     ]
    }
   ],
   "source": [
    "# ðŸ”¹ Set N as the number of rows in the dataset\n",
    "N = len(df)  # Use all the available data\n",
    "\n",
    "# ðŸ”¹ Get the most recent data up to today\n",
    "today_data = df.iloc[-N:]  # This now includes all the data in the dataset\n",
    "\n",
    "# Prepare the feature set for the next 21 days prediction\n",
    "future_predictions_rain = []\n",
    "future_predictions_numerical = {}\n",
    "\n",
    "# Predict for the next 21 days using the trained RandomForestClassifier and RandomForestRegressor\n",
    "for day in range(1, 22):  # For 21 days ahead\n",
    "    print(f\"\\nðŸ”¹ Predicting for Day {len(df) + day}...\")\n",
    "\n",
    "    # Prepare the features for this prediction\n",
    "    future_features = today_data.drop(columns=['rain_or_not']).values.flatten().reshape(1, -1)\n",
    "\n",
    "    # Predict 'rain_or_not' for the next day\n",
    "    future_rain_prediction = best_classifier.predict(future_features)\n",
    "    future_predictions_rain.append(future_rain_prediction[0])\n",
    "\n",
    "    # Now update today_data for the next iteration\n",
    "    future_rain = future_rain_prediction[0]  # 1 for Rain, 0 for No Rain\n",
    "\n",
    "    # Add the prediction to the 'rain_or_not' column for future prediction\n",
    "    future_row = today_data.copy()\n",
    "    future_row['rain_or_not'] = future_rain\n",
    "\n",
    "    # Update today's data to include the new prediction (simulate the next day)\n",
    "    today_data = pd.concat([today_data, future_row]).iloc[1:]\n",
    "\n",
    "    # For each numerical column, predict future values using RandomForestRegressor\n",
    "    for target_col in numerical_columns:\n",
    "        future_numerical_prediction = best_model.predict(future_features)\n",
    "        if target_col not in future_predictions_numerical:\n",
    "            future_predictions_numerical[target_col] = []\n",
    "        future_predictions_numerical[target_col].append(future_numerical_prediction[0])\n",
    "\n",
    "# Output predictions for the next 21 days\n",
    "print(\"\\nðŸ”¹ Future Predictions for 'rain_or_not' (Next 21 Days):\")\n",
    "for i, rain in enumerate(future_predictions_rain):\n",
    "    print(f\"  Day {len(df) + i + 1}: Predicted = {'Rain' if rain == 1 else 'No Rain'}\")\n",
    "\n",
    "# Output predictions for numerical features\n",
    "print(\"\\nðŸ”¹ Future Predictions for Numerical Features (Next 21 Days):\")\n",
    "for target_col in future_predictions_numerical:\n",
    "    print(f\"\\nðŸ”¹ Predictions for {target_col}:\")\n",
    "    for i, prediction in enumerate(future_predictions_numerical[target_col]):\n",
    "        print(f\"  Day {len(df) + i + 1}: Predicted {target_col} = {prediction:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
